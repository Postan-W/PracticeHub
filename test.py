# from sklearn.cluster import SpectralClustering
import pandas as pd
import numpy as np
# import datetime
# data = pd.read_csv("iris.csv").drop(columns=["target","Unnamed: 0"])
# data = data.values
# model = SpectralClustering(n_clusters=3,gamma=0.1)
# # result = model.fit_predict(data)
# start = datetime.datetime.now()
# model.fit(data)
# end = datetime.datetime.now()
# print("用时{}".format(end-start))
# print(model.fit_predict(data))
# print(type(model.labels_))
# from base import *
# from pyspark.ml.feature import StringIndexer,VectorAssembler
# data = spark.createDataFrame([[1,2,"a"],[2,3,"b"],[3,4,"c"],[3,4,"c"],[3,4,"c"],[3,4,"c"],[3,4,"c"],[3,4,"c"],[3,4,"c"]],schema=["happy","every","day"])
# data2 = spark.createDataFrame([[3,4,"a"],[5,6,"b"]],schema=["ha","ev","day"])
# indexed = StringIndexer(inputCol="day",outputCol="dayIndexed").fit(data)
# data3 = indexed.transform(data)
# vectorassembler = VectorAssembler(inputCols=["happy","every"],outputCol="vector")
# vector = vectorassembler.transform(data3)
# vector.show()

print("adsad.dsf.asdf".rfind("."))